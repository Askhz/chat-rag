Name: chat-rag
Host: 0.0.0.0
Port: 8888

# Token processing configuration
TokenThreshold: 100_000

# Logging configuration
LogFilePath: "logs/"
LokiEndpoint: "http://localhost:3100/loki/api/v1/push"
LogScanIntervalSec: 10

# Model configuration
SummaryModel: "qwen2.5-coder-32b"
SummaryModelTokenThreshold: 64_000
ClassifyModel: "qwen2.5-coder-32b"

# Split system prompt, used to compress system prompt
SystemPromptSplitStr: "====\n\nRULES"

# used recent user prompt messages nums
RecentUserMsgUsedNums: 3

# Department configuration
DepartmentApiEndpoint: "http://localhost:1234/work_id?work_id="

# Models supported by function calling
LLM:
  # Endpoint: "https://zgsm.sangfor.com/chat-rag/api/v1/chat/completions"
  Endpoint: "http://127.0.0.1:30616/v1/chat/completions"
  FuncCallingModels:
    - "deepseek-v3"
    - "qwen3*"
    - "claude*"

Redis:
  Addr: "127.0.0.1:6379"

# Semantic API configuration
Tools:
  SemanticSearch:
    SearchEndpoint: "http://127.0.0.1:18888/codebase-embedder/api/v1/search/semantic"
    ApiReadyEndpoint: "http://127.0.0.1:18888/codebase-embedder/api/v1/embeddings/summary"
    TopK: 10
    ScoreThreshold: 0.7